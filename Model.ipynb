{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest,f_regression,mutual_info_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv',index_col = 0)\n",
    "X_predict= pd.read_csv('X_predict.csv',index_col = 0)\n",
    "y = pd.read_csv('y.csv',header = None,  names=['Id', 'price'],index_col = 0).iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation function and grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model,x_in):\n",
    "    kf = KFold(n_folds, shuffle=True).get_n_splits(x_in)\n",
    "    rmse= np.sqrt(-cross_val_score(model, x_in, y_train.values, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,x_in,param_grid):\n",
    "        kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x_in)\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=kf, scoring=\"neg_mean_squared_error\", n_jobs=-1,verbose=2)\n",
    "        grid_search.fit(x_in, y_train.values)\n",
    "        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n",
    "        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examing num of feature used in the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(X_train, y, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0006))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xc23b6a0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbc44ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "num_feats_ = np.arange(100,286,2)\n",
    "cv_score = []\n",
    "test_score = []\n",
    "for num_feats in num_feats_: \n",
    "    X_new = SelectKBest(f_regression, k= num_feats).fit_transform(train.values, y_train.values)\n",
    "    \n",
    "    kf = KFold(n_folds, shuffle=True).get_n_splits(X_new)\n",
    "    score= np.sqrt(-cross_val_score(lasso, X_new, y_train.values, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    cv_score.append(score.mean())\n",
    "    \n",
    "\n",
    "plt.plot(num_feats_,cv_score,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 580 features to do the training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso score: 0.11402 (0.00766)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid(Lasso()).grid_get(train.values,{'alpha': [0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007]})\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0004, random_state=1))\n",
    "score= rmsle_cv(lasso,train.values)\n",
    "print(\"Lasso score: {:.5f} ({:.5f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 0.11414 (0.00751)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid(ElasticNet()).grid_get(X_new,{'alpha': [0.0006,0.0007,0.0008,0.0009],'l1_ratio':[0.8,0.9,1,1.1],'max_iter':[700,800,900,1000,1100]})\n",
    "\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0004, l1_ratio=1.4,max_iter = 600))\n",
    "\n",
    "score = rmsle_cv(ENet,train.values)\n",
    "print(\"ElasticNet score: {:.5f} ({:.5f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge score: 0.1154 (0.0080)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grid(KernelRidge()).grid_get(X_new,[{'kernel': ['linear'],'alpha':np.logspace(-4,4,8)},{'kernel': ['polynomial'],'alpha':np.logspace(-4,4,8),'degree':np.logspace(-4,4,8),'coef0':np.logspace(-4,4,8)}])\n",
    "\n",
    "KRR = KernelRidge(alpha=0.04, kernel='polynomial', degree=1, coef0=0.0008)\n",
    "\n",
    "score = rmsle_cv(KRR,train.values)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 0.16454 (0.01919)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid(KNeighborsRegressor()).grid_get(X_new,{'n_neighbors':np.arange(5,50,5), 'weights':['uniform','distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size':np.arange(5,50,5), 'p':np.arange(2,20,2)})\n",
    "\n",
    "\n",
    "KNN = make_pipeline(RobustScaler(), KNeighborsRegressor(n_neighbors=6, weights = 'distance',algorithm='brute', p=1, leaf_size=1))\n",
    "\n",
    "score = rmsle_cv(KNN,train.values)\n",
    "print(\"KNN score: {:.5f} ({:.5f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid(SVR()).grid_get(X_new,{'kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'degree':[1,2,3,4,5], 'coef0':[0.0,0.1,0.2,1,10],'C':[0.01,0.1,1.0,10], 'epsilon':[0.01,0.1,1,10]})\n",
    "\n",
    "#{'coef0': 0.0, 'epsilon': 0.02, 'kernel': 'linear', 'C': 0.004, 'degree': 1} 0.11325162650394656\n",
    "\n",
    "# SVR = make_pipeline(RobustScaler(), SVR(kernel='poly', degree=1, coef0=1,C=9.0, epsilon=0.01))\n",
    "\n",
    "# score = rmsle_cv(SVR,X_new)\n",
    "# print(\"SVR score: {:.5f} ({:.5f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score: 0.13041 (0.01426)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid(RandomForestRegressor()).grid_get(X_new,{'n_estimators':[100,1000,5000], 'max_depth':[None,2,5,10,20], 'min_samples_split':[2,5,10], 'min_samples_leaf':[1,2,3,5,10], 'max_features':[0.01,0.05,0.1,0.5,1]})\n",
    "\n",
    "\n",
    "RF = make_pipeline(RobustScaler(), RandomForestRegressor(n_estimators=500, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=0.3))\n",
    "\n",
    "score = rmsle_cv(RF,train.values)\n",
    "print(\"RF score: {:.5f} ({:.5f})\\n\".format(score.mean(), score.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.1151 (0.0097)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#{'min_samples_leaf': 4, 'max_features': 0.04, 'min_samples_split': 30, 'n_estimators': 3700, 'learning_rate': 0.01, 'max_depth': 3, 'loss': 'ls'} 0.1122755329486732\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3700, learning_rate=0.04,\n",
    "                                   max_depth=3, max_features=0.04,\n",
    "                                   min_samples_leaf=4, min_samples_split=30, \n",
    "                                   loss='ls')\n",
    "score = rmsle_cv(GBoost,train.values)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 0.1156 (0.0120)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid(xgb.XGBRegressor()).grid_get({'colsample_bytree':[0.1,0.4603], 'gamma':[0.01,0.0468], 'learning_rate':[0.01,0.05], 'max_depth':[3,10], 'min_child_weight':[1.7817,10], 'n_estimators':[2000,5200],'reg_alpha':[0.4640,1], 'reg_lambda':[0.5,0.9],'subsample':[0.1,0.5213]})\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05, max_depth=3, min_child_weight=1.7817, n_estimators=5200,reg_alpha=0.4640, reg_lambda=0.9,subsample=0.5213, silent=1,nthread = -1)\n",
    "\n",
    "score = rmsle_cv(model_xgb,train.values)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 0.1157 (0.0095)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid(lgb.LGBMRegressor()).grid_get(X_new,{'num_leaves':[3],'learning_rate':[0.05], 'n_estimators':[1000],'max_bin' : [220,250,270], 'bagging_fraction' : [0.8],'bagging_freq' : [12,14,16,18], 'feature_fraction' : [0.1],'min_data_in_leaf' :[4,5,6], 'min_sum_hessian_in_leaf' : [2,4,6,8]})\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=3,learning_rate = 0.05, n_estimators=1000, max_bin = 250, bagging_fraction = 0.8,bagging_freq = 16, feature_fraction = 0.1,bagging_seed=9,min_data_in_leaf =5, min_sum_hessian_in_leaf = 2)\n",
    "\n",
    "\n",
    "score = rmsle_cv(model_lgb,train.values)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplest Stacking approach : Averaging base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.1091 (0.0091)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (lasso,ENet, KRR, GBoost,model_xgb, model_lgb))\n",
    "\n",
    "score = rmsle_cv(averaged_models,train.values)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Less simple Stacking : Adding a Meta-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1089 (0.0089)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (lasso, GBoost, KRR),\n",
    "                                                 meta_model = ENet)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models,train.values)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1457, 287)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(train.values, y_train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(X_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(train.values, y_train.values)\n",
    "\n",
    "model_xgb_pred = np.expm1(model_xgb.predict(X_predict.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.fit(train.values, y_train.values)\n",
    "model_lgb_pred = np.expm1(model_lgb.predict(X_predict.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.8 + model_xgb_pred*0.1 + model_lgb_pred*0.1\n",
    "\n",
    "submission_df = pd.DataFrame(data= {'Id' :X_predict.index, 'SalePrice': ensemble})\n",
    "\n",
    "submission_df.head()\n",
    "\n",
    "submission_df.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
